{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmHz9rKQLUxSrb2nAVGCw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcosbenicio/deep_learning_classification/blob/main/classificador_05_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfBdQeOoJA2P"
      },
      "source": [
        "# Classificador para os dígitos $0$ e $5$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuvHB8JwHvom"
      },
      "source": [
        "Instalação manual de pacote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj5s87T8H26q"
      },
      "source": [
        "!pip install -Uqq fastbook"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGMXK_tNH71F"
      },
      "source": [
        "Biblioteca fastai permite usar funções para rapidamente construir uma rede neuronal e treinar nosso modelo de diferenciar $0$ e $5$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8RnfwNnH649"
      },
      "source": [
        "import fastbook\n",
        "from fastai.vision.all import *\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "import numpy as np\n",
        "\n",
        "# Muda a escala de cor padrão da imagem para escala de cinza.\n",
        "matplotlib.rc('image', cmap='Greys')\n",
        "\n",
        "import PIL as pl\n",
        "import torch as t\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkcMKQcKW5Al"
      },
      "source": [
        "Primeiro passamos o caminho do diretório dataset MINST para a variável path. Nesse diretório temos imagens para todos os dígitos de $0$ à $9$. Em seguida, com o código (/path/...).ls( ), é possível listar o conteúdo dentro desse diretório. Temos portanto a pasta 'training' e 'testing', e dentro de cada um delas mais outros $10$ diretórios referentes aos números de $0$ à $9$. Esse método retorna uma lista contendo os caminhos dos arquivos de imagem, cada posição da lista têm armazenado o caminho para um arquivo de imagem.\n",
        "\n",
        "Por ultimo, nessa célula, vamos criar quatro listas com os caminhos dos arquivos em ordem crescente. Teremos duas listas contendo todas os caminhos das imagens de $0$s(zeros) presentes nos diretórios 'training' e 'testing', e outros duas listas para as imagens de $5$s(cincos). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrDzS7cGIBRN"
      },
      "source": [
        "# Armazena o caminho para o diretório do dataset MNIST numa variável.\n",
        "path = untar_data(URLs.MNIST)\n",
        "\n",
        "# Para o diretório 'training' \n",
        "zeros_train = (path/'training'/'0').ls().sorted()\n",
        "cincos_train = (path/'training'/'5').ls().sorted()\n",
        "\n",
        "# Para o diretório 'testing' \n",
        "zeros_test = (path/'testing'/'0').ls().sorted()\n",
        "cincos_test = (path/'testing'/'5').ls().sorted()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xoQ-tnewjzi"
      },
      "source": [
        "Criarei quatro listas contendo tensores de segunda ordem (matrizes)  de dimensão $28\\times28$ representando cada uma das imagens. Portanto ficarei com duas listas contendo todas as imagens de $0$ dos diretórios 'training' e 'testing', e outras duas listas para as imagens de $5$. \n",
        "\n",
        "Além disso, vamos empacotar cada lista num tensor de primeira ordem (vetor) usando o método stack da biblioteca Pytorch. Irei também normalizar o tensor para os elementos do ultimo eixo assumirem valores entre $0$ e $1$.\n",
        "Para o diretório de zeros, por exemplo, o tensor que definiremos como zeros_train_tensor terá $5923$ matrizes de dimensão $28\\times28$.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0XERhkaIPJd"
      },
      "source": [
        "# Para o diretório 'training'\n",
        "zeros_train_list = [tensor(Image.open(i)) for i in zeros_train]\n",
        "cincos_train_list = [tensor(Image.open(i)) for i in cincos_train]\n",
        "\n",
        "zeros_train_tensor = t.stack(zeros_train_list).float()/255\n",
        "cincos_train_tensor = t.stack(cincos_train_list).float()/255\n",
        "\n",
        "# Para o diretório 'testing'\n",
        "zeros_test_list = [tensor(Image.open(i)) for i in zeros_test]\n",
        "cincos_test_list = [tensor(Image.open(i)) for i in cincos_test]\n",
        "\n",
        "zeros_test_tensor = t.stack(zeros_test_list).float()/255\n",
        "cincos_test_tensor = t.stack(cincos_test_list).float()/255\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfyVz1DrmqJG"
      },
      "source": [
        "Nossa variável independente $x$ serão as imagens $0$s e $5$s do diretório 'training' concatenanas num único tensor x_train. Para isso usarei o método view, que  muda o formato do tensor sem alterar seu conteúdo. O $-1$ é um parametro especial que pega o tamanho necessário de um eixo para caber todos os dados.\n",
        "\n",
        "O tensor y_train armazenará o rótulo referente a cada imagem do tensor x_train. O método unsqueeze(1) adiciona uma dimensão ao tensor, ficando equiparável ao rank do tensor x_train. O mesmo processo vai ser feito também para o diretório 'testing', que chamarei de x_test e y_test.\n",
        "\n",
        "Além disso, usando a função zip podemos colocar elementos de mesmo indice e diferentes tensores como elementos de uma mesma tupla (x,y). Portanto, relacionariamos cada imagem de x_test com um rótulo de y_test através das tuplas (x,y) como um conjunto de pontos de um gráfico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWxKk4KJIocd"
      },
      "source": [
        "# Para o diretório 'training'\n",
        "x_train = t.cat([zeros_train_tensor, cincos_train_tensor]).view(-1, 28*28)\n",
        "y_train = tensor([0]*len(zeros_train) + [1]*len(cincos_train)).unsqueeze(1)\n",
        "\n",
        "dset_train = list(zip(x_train, y_train))\n",
        "\n",
        "# Para o diretório 'testing'\n",
        "x_test = t.cat([zeros_test_tensor, cincos_test_tensor]).view(-1, 28*28)\n",
        "y_test = tensor([0]*len(zeros_test) + [1]*len(cincos_test)).unsqueeze(1)\n",
        "\n",
        "dset_test = list(zip(x_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thkb3PmsOM_S"
      },
      "source": [
        "Vamos inicializar um tensor usando o método randn(size) dentro da função inicia_parametros( )  que vamos definir. Essa função recebe o número total de pixels presentes nas imagens, que no nosso caso são $28 \\times 28=784$ pixels.\n",
        "Usando essa função teremos dois tensores, weight (peso) e bias. .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgbnr-hY4Wv9"
      },
      "source": [
        "def inicia_parametros(num_pixel): return (t.randn(num_pixel))\n",
        "\n",
        "weights = inicia_parametros((28*28,1))\n",
        "bias = inicia_parametros(1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37F6T3RHrmmh"
      },
      "source": [
        "Escrevemos uma função do tipo:\n",
        "$$ \\vec{y} = {X}.\\vec{w} +b$$\n",
        "onde $\\vec{Y}$ é um vetor, $X$ um tensor e $b$ um escalar. A ideia é evitr o uso de loops, trocando por um produto entre tensores. Isso fornecerá y_previsao, que serão os valores que melhor se aproximam de y_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExIbOFR0LJaT"
      },
      "source": [
        "def linear1(xb): return xb@weights + bias\n",
        "y_previsao = linear1(x_train)\n",
        "\n",
        "#print(y_previsao)\n",
        "#print(y_train)\n",
        "#print(weights[:4])\n",
        "#print(bias)\n",
        "# previsao seriam os valores de y proximos do valor ideal.\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p_xyqXudAAm"
      },
      "source": [
        "Queremos comparar os tensores y_previsao e y_train de rank-1.\n",
        "\n",
        "\n",
        "Usando operadores booleanos vamos crir um tensor com variáveis 0(false), se o valor for  menor que $0.5$ e 1(true) no caso contrário. Note que mesmo sendo um tensor de zeros e uns ele é definido como float. Em seguida usando o condicional $==$ vamos comparar com os valores presentes no tensor y_train. Lembre que y_train é o tensor de rank-1 contendo  os rótulos $0$ e $1$ das imagens presentes no tensor x_train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Irlt4AqFLNOa",
        "outputId": "9de80513-a403-4276-bd8b-0221956923ae"
      },
      "source": [
        "correta = (y_previsao > 0.5).float() == y_train\n",
        "data_correta.float().mean().item()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4c153417bb63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorreta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_previsao\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_correta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_correta' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_qsGXLZHaXV"
      },
      "source": [
        "A função t.where(a,b,c) vai medir a distancia do valor da previsão com relação a 1 e quão distante é de zero para em seguir tirar a média de todas as distancias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFkxM6xNRr-A"
      },
      "source": [
        "def mnist_loss(y_previsao, alvo):\n",
        "    return t.where(alvos==1, 1-y_previsao, previsao).mean()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Ra5_cXChQO"
      },
      "source": [
        "dl_train = DataLoader(dset_train, batch_size=256)\n",
        "dl_test = DataLoader(dset_test, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia1YRXmmrLv5"
      },
      "source": [
        "Separarei os dados de x_train em batchs, como se fossem pequenos pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_oQ7ks7C5-E"
      },
      "source": [
        "batch = x_train[0:4]\n",
        "previsa = linear1(batch)\n",
        "\n",
        "loss = mnist_loss(previsa, y_train[:4])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}